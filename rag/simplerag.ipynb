{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify that the API key is set\n",
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF Reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(\"Kaavish_Proposal.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Splitter to break down PDF into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot_app.py\n",
    "import streamlit as st\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, Column, Integer, Text, Numeric\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database URL\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"postgresql://neondb_owner:npg_wNTU4WiDqJQ5@ep-square-tooth-a1szbuny-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require\")\n",
    "\n",
    "# Create database engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Create a configured \"Session\" class\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# Create a Session\n",
    "session = Session()\n",
    "\n",
    "# Define the base class for declarative class definitions\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the table schema\n",
    "class Product(Base):\n",
    "    __tablename__ = 'shahzar_table'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(Text, nullable=False)\n",
    "    price = Column(Numeric(10, 2), nullable=False)\n",
    "    image = Column(Text, nullable=False)\n",
    "    url = Column(Text, nullable=False)\n",
    "    store = Column(Text, nullable=False)\n",
    "\n",
    "# Create the table (if it doesn't exist)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Example function to query the database\n",
    "def get_all_products():\n",
    "    results = session.query(Product).all()\n",
    "    return results\n",
    "\n",
    "# Example function to get product info\n",
    "def get_product_info(product_name):\n",
    "    result = session.query(Product).filter(Product.name == product_name).first()\n",
    "    return result\n",
    "\n",
    "# Ingest data into vector database with chunking\n",
    "def ingest_data():\n",
    "    products = get_all_products()\n",
    "    initial_documents = [\n",
    "        Document(\n",
    "            metadata={\n",
    "                \"id\": product.id,\n",
    "                \"name\": product.name,\n",
    "                \"price\": str(product.price),\n",
    "                \"image\": product.image,\n",
    "                \"url\": product.url,\n",
    "                \"store\": product.store\n",
    "            },\n",
    "            page_content=f\"{product.name} {product.price} {product.store}\"\n",
    "        )\n",
    "        for product in products\n",
    "    ]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    documents = text_splitter.split_documents(initial_documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_db = FAISS.from_documents(documents, embeddings)\n",
    "    return vector_db\n",
    "\n",
    "# Initialize vector database\n",
    "vector_db = ingest_data()\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Price Contrast: Your Personal Shopping Assistant\")\n",
    "\n",
    "# Product Search\n",
    "st.header(\"Search for Products\")\n",
    "query = st.text_input(\"Enter product name or description\", \"Blue Shirt\")\n",
    "if st.button(\"Search\"):\n",
    "    results = vector_db.similarity_search(query)\n",
    "    if results:\n",
    "        for result in results:\n",
    "            st.write(f\"**Name:** {result.metadata['name']}\")\n",
    "            st.write(f\"**Price:** {result.metadata['price']}\")\n",
    "            st.write(f\"**Store:** {result.metadata['store']}\")\n",
    "            st.write(f\"**URL:** [Link]({result.metadata['url']})\")\n",
    "            st.image(result.metadata['image'])\n",
    "            st.write(\"---\")\n",
    "    else:\n",
    "        st.write(\"No products found.\")\n",
    "\n",
    "# Product Details\n",
    "st.header(\"Get Product Details\")\n",
    "product_name = st.text_input(\"Enter product name for details\", \"Product A\")\n",
    "if st.button(\"Get Details\"):\n",
    "    product_info = get_product_info(product_name)\n",
    "    if product_info:\n",
    "        st.write(f\"**Name:** {product_info.name}\")\n",
    "        st.write(f\"**Price:** {product_info.price}\")\n",
    "        st.write(f\"**Store:** {product_info.store}\")\n",
    "        st.write(f\"**URL:** [Link]({product_info.url})\")\n",
    "        st.image(product_info.image)\n",
    "    else:\n",
    "        st.write(\"Product not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvector_db\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Black\"\n",
    "results = vector_db.similarity_search(query)\n",
    "print(results[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001D8CDE0B4D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001D8CDE0B7A0>, root_client=<openai.OpenAI object at 0x000001D8CD98C290>, root_async_client=<openai.AsyncOpenAI object at 0x000001D8CDE0B530>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions based on only the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds your answer helpful.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document Chain \n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mRetrievers: A retriever is an interface that returns documents given\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m an unstructured query. It is more general than a vector store.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m https://python.langchain.com/docs/modules/data_connection/retrievers/   \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m retriever\u001b[38;5;241m=\u001b[39m\u001b[43mvector_db\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m     11\u001b[0m retriever\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrievers: A retriever is an interface that returns documents given\n",
    " an unstructured query. It is more general than a vector store.\n",
    " A retriever does not need to be able to store documents, only to \n",
    " return (or retrieve) them. Vector stores can be used as the backbone\n",
    " of a retriever, but there are other types of retrievers as well. \n",
    " https://python.langchain.com/docs/modules/data_connection/retrievers/   \n",
    "\"\"\"\n",
    "\n",
    "retriever=vector_db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieval chain:This chain takes in a user inquiry, which is then\n",
    "passed to the retriever to fetch relevant documents. Those documents \n",
    "(and original inputs) are then passed to an LLM to generate a response\n",
    "https://python.langchain.com/docs/modules/chains/\n",
    "\"\"\"\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"Tell me about the most expensive black shirt?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the most expensive black shirt is the Black Iconic POLO priced at 3290.00.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
